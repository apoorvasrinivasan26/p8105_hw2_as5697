---
title: "Homework_2"
author: "Apoorva Srinivasan"
date: "10/2/2018"
output: github_document
---
```{r}
library(tidyverse)
library(ggplot2)
library(readxl)
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r p1.1}

nyc_transit = read_csv(file = "./hw2_data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") 
  nyc_transit = janitor::clean_names(nyc_transit) %>%
    select(line:entry, vending, ada) %>%
    mutate(entry = recode(entry, "YES" = TRUE, "NO" = FALSE ))
  
```

We're given a dataset containing information about nyc transit subway entrance and exit details. After editing out what is not required for this homework, we now have a new dataset with variable that are line, station name, station lattitude, longitude, route 1 to 11, entrance type, entry, vending and compliance with ADA.

Data cleaning steps

* Imported data using read_csv through relative path to ensure reproducability
* Cleaned the variable names using the janitor function which converted all column names into lower snake case.
* Retained the required variables using select to declutter our data.
* Converted the entry variable from character to logical variable using recode.

The dimensions of the data set are  `r nrow(nyc_transit)` x `r ncol(nyc_transit)`. 

Are these data tidy?

No, the data doesn't look tidy because the data for the route variable are spread across eleven columns which makes it difficult to read. 

__Further questions:__


How many distinct stations are there?
```{r p1.2}
distinct(nyc_transit, line, station_name, .keep_all = TRUE) %>%
  nrow()
```

How many stations are ADA compliant?

```{r p1.3}
 nyc_transit %>%
  distinct(station_name, line, .keep_all = TRUE) %>% 
  filter(ada == TRUE) %>% 
  nrow()

```

No. of ADA stations are 84


What proportion of station entrances / exits without vending allow entrance?



```{r p1.4}
no_vending = nyc_transit %>%
  filter(vending == "NO")
  proportion_no_vending = mean(no_vending$entry == TRUE)
  knitr::kable(proportion_no_vending)
```
Therefore, 37.7% of stations with entrance don't have vending machines.

Reformating the data 

```{r p1.5}
nyc_transit = gather(nyc_transit, key = route_number, value = route_name, route1:route11) %>%
  separate(route_number, into = c("route_str", "route_number"), sep = 5) %>%
  select(-route_str)
```


How many distinct stations serve the A train?
```{r p1.6}
  nyc_transit %>%
  distinct(station_name, line, .keep_all = TRUE) %>%
  filter(route_name == "A") %>%
  nrow()
```

Of the stations that serve the A train, how many are ADA compliant?

```{r}
nyc_transit %>%
  distinct(station_name, line, .keep_all = TRUE) %>%
  filter(route_name == "A", ada == "TRUE") %>%
  nrow()
```



__PROBLEM 2__
```{r}
trash_wheel = read_excel("./hw2_data/HealthyHarborWaterWheelTotals2018-7-28.xlsx", sheet = "Mr. Trash Wheel", range = cell_cols("A:N"), col_names = TRUE) %>%
  janitor::clean_names() %>% 
  filter(!(dumpster == "NA")) %>% 
  mutate(sports_balls = round(sports_balls)) %>% 
  mutate(sports_balls = as.integer(sports_balls))
```


### Problem 2.2: Reading and cleaning precipitation data for 2016 and 2017
```{r}
precipitation_2016 = read_excel("./hw2_data/HealthyHarborWaterWheelTotals2018-7-28.xlsx", sheet = "2016 Precipitation", range = "A2:B14", col_names = TRUE) %>%
  janitor::clean_names() %>% 
  rename(precipitation = total) %>% 
  filter(!is.na(precipitation)) %>% 
  mutate(year = 2016)
```

```{r}
precipitation_2017 = read_excel("./hw2_data/HealthyHarborWaterWheelTotals2018-7-28.xlsx", sheet = "2017 Precipitation", range = "A2:B14", col_names = TRUE) %>% 
  janitor::clean_names() %>% 
  rename(precipitation = total) %>% 
  filter(!is.na(precipitation)) %>% 
  mutate(year = 2017)
```

Mr. Trash wheel is a water wheel vessel set up in 2014 designed to remove trash flowing down the Jones Fall river in Baltimore state. The data was collected a few times a month from May 2014 through July 2018. The given dataset contains information on dumpster number, date of trash collection, the amount of trash(by weight and volume), it's contents(plastic bottles, cigarette buds,bags etc.) and the approximate number of homes powered using the energy generated from the trash. The key variables would be the date, amount(by weight and volume) and the number of homes powered. After cleaning the data, we get a new datset with `r nrow(trash_wheel)` rows and `r ncol(trash_wheel)` columns. The approximate total number of homes that were powered by using `r trash_wheel %>% pull(weight_tons) %>% sum()` tons of trash collected by Mr. Trash Wheel are `r trash_wheel %>% pull(homes_powered) %>% sum()`.


Combining datasets:

```{r}
precipitation_combined = 
  bind_rows(precipitation_2016, precipitation_2017) %>% 
  mutate(month = month.name[month])
```

* For available data, what was the total precipitation in 2017? 

```{r}
sum(precipitation_2017$precipitation)
```
The total precipitation in 2017 is `r sum (precipitation_2017$precipitation)`

* What was the median number of sports balls in a dumpster in 2016?

```{r}
  trash_wheel %>%  
  filter(year == 2016) %>% 
  pull(sports_balls) %>% 
  median
```

The median number of sports balls in a dumpster in 2016 are 26.


__PROBLEM 3__

```{r p3.1}
library(p8105.datasets)

#View(p8105.datasets::brfss_smart2010)
```


```{r}
brfss_data = p8105.datasets::brfss_smart2010 %>%
  janitor::clean_names() %>%
  rename("state" = locationabbr, "county" = locationdesc) %>% 
  filter(topic == "Overall Health") %>%
  select(-class, -topic, -question, -sample_size, -c(confidence_limit_low:geo_location)) %>%
  spread(key = response, value = data_value) %>%
  janitor::clean_names() %>%
  mutate(excellent_or_verygood = excellent + very_good)

```

Further questions:

How many unique locations are included in the dataset? Is every state represented? 

```{r}
brfss_data %>%
  distinct(state) %>% 
  count()
```

All 50 states and 1 US Territory, the District of Columbia are represented in the Table.

What state is observed the most?

```{r}
most_obv = brfss_data %>%
  count(state) %>% 
  arrange(desc(n, state)) %>%
  head(1)
```
The most observed state is `r most_obv`

In 2002, what is the median of the “Excellent” response value?

```{r}
excellent_2002 =
  brfss_data %>% 
  filter(year == 2002) %>%
  select(excellent) 
```

The median of "excellent" responses in 2002 is `r median(excellent_2002$excellent, na.rm = TRUE)`

Make a histogram of “Excellent” response values in the year 2002.

```{r}
hist(excellent_2002$excellent, main = " Excellent response values in 2002", xlab = "excellent values", col = c("grey") )
```


Make a scatterplot showing the proportion of “Excellent” response values in New York County and Queens County (both in NY State) in each year from 2002 to 2010.

```{r}
brfss_data %>%
filter(county %in% c("NY - Queens County", "NY - New York County" )) %>% 
  ggplot(., aes(x = year, y = excellent)) +
  geom_point(aes(color = county)) + 
  labs(main = "Scatterplot showing proportion of Excellent response values in New York County and Queens County", x = "year", y = "Proportion of Excellent Responses")
```




